{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "import pdfplumber\n",
    "import jieba\n",
    "import jieba.posseg as pseg #词性标注\n",
    "import jieba.analyse as anls #关键词提取\n",
    "from sklearn.cluster import KMeans\n",
    "from gensim.models.doc2vec import Doc2Vec,TaggedDocument\n",
    "from docx import Document\n",
    "from io import StringIO\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "from collections import Counter\n",
    "class Template():\n",
    "    def __init__(self,type):\n",
    "        self._type = type\n",
    "\n",
    "    def re_match(self,texts):\n",
    "        \"\"\"匹配技术部分小节\"\"\"\n",
    "        pattern = \"第.*节\"\n",
    "        regex = re.compile(pattern)\n",
    "        sections = []\n",
    "        index = 0\n",
    "        for text in texts:\n",
    "            if len(regex.findall(text)) > 0:\n",
    "                sections.append((index, text))\n",
    "            #             print(text,index)\n",
    "            index += 1\n",
    "        return sections\n",
    "    def get_sections(self,dirname):\n",
    "        \"\"\"获取小节\"\"\"\n",
    "        sections = {}\n",
    "        text_extract = {}\n",
    "        for _, _, files in os.walk(dirname):\n",
    "            for filename in files:\n",
    "                if filename.split('.')[-1] == 'pdf':\n",
    "                    texts = pdf_parse_text(dirname + '/' + filename)\n",
    "                    text_extract[filename.split('.')[0]] = texts\n",
    "                    sections_ = re_match(texts)\n",
    "                    sections[filename.split('.')[0]] = sections_\n",
    "                    print(\"{}小节获取完毕\".format(filename))\n",
    "        return sections, text_extract\n",
    "\n",
    "def pdf_parse_table(path):\n",
    "    \"\"\"解析pdf文件中的表格\"\"\"\n",
    "    origin = pdfplumber.open(path)\n",
    "    tables = []\n",
    "    for page in origin.pages:\n",
    "        # 获取当前页面的全部表格\n",
    "        table_page = [table for tables in page.extract_tables() for table in tables if len(table)!=0]\n",
    "        tables.append(table_page)\n",
    "    origin.close()\n",
    "    return tables\n",
    "\n",
    "def pdf_parse_text(path):\n",
    "    \"\"\"解析pdf为\"\"\"\n",
    "    origin = pdfplumber.open(path)\n",
    "    texts = []\n",
    "    for page in origin.pages:\n",
    "        text_page = [text.replace(' ','') for text in page.extract_text().split('\\n') if len(text.replace(' ','')) != 0]\n",
    "        texts.extend(text_page)\n",
    "    origin.close()\n",
    "    return texts\n",
    "\n",
    "def re_match(texts):\n",
    "    \"\"\"匹配技术部分小节\"\"\"\n",
    "    pattern = \"第.*节\"\n",
    "    regex = re.compile(pattern)\n",
    "    sections = []\n",
    "    index = 0\n",
    "    for text in texts:\n",
    "        if len(regex.findall(text)) > 0:\n",
    "            sections.append((index,text))\n",
    "#             print(text,index)\n",
    "        index+=1\n",
    "    return sections\n",
    "\n",
    "def get_sections(dirname):\n",
    "    \"\"\"获取小节\"\"\"\n",
    "    sections = {}\n",
    "    text_extract = {}\n",
    "    for _,_,files in os.walk(dirname):\n",
    "        for filename in files:\n",
    "            if filename.split('.')[-1] == 'pdf':\n",
    "                texts = pdf_parse_text(dirname+'/'+filename)\n",
    "                text_extract[filename.split('.')[0]] = texts\n",
    "                sections_ = re_match(texts)\n",
    "                sections[filename.split('.')[0]] = sections_\n",
    "                print(\"{}小节获取完毕\".format(filename))\n",
    "    return sections,text_extract\n",
    "\n",
    "def get_exact_section(dirname,numberlist):\n",
    "    \"\"\"获取解析的小节列表\"\"\"\n",
    "    sections = []\n",
    "    for _,_,files in os.walk(dirname):\n",
    "        for filename in files:\n",
    "            if filename.split('.')[-1] == 'pdf':\n",
    "                texts = pdf_parse_text(dirname+'/'+filename)\n",
    "                try:\n",
    "                    section_exact = texts[numberlist[filename.split('.')[0]][0]:numberlist[filename.split('.')[0]][1]]\n",
    "                    sections.append((filename.split('.')[0],section_exact))\n",
    "                except:\n",
    "                    pass\n",
    "                print(\"{}小节获取完毕\".format(filename))\n",
    "    return sections\n",
    "def get_cross(sections):\n",
    "    \"\"\"获取公有的篇章\"\"\"\n",
    "    set1 = {sectionname[3:] for _, sectionname in list(sections.values())[0]}\n",
    "    for label, sections_ in sections.items():\n",
    "        set2 = {sectionname[3:] for _, sectionname in list(sections_)}\n",
    "        if (len(set2) > 0):\n",
    "            # print(set2)\n",
    "            set1 = set1 & set2\n",
    "            print(set1)\n",
    "    counter = Counter()\n",
    "    for label, sections_ in sections.items():\n",
    "        set2 = {sectionname[3:] for _, sectionname in list(sections_)}\n",
    "        if (len(set2) > 0):\n",
    "            set3 = set2 - set1\n",
    "            counter.update(set3)\n",
    "    summary = len(sections)\n",
    "    for item, count in counter.items():\n",
    "        if (count > summary * 0.5):\n",
    "            set1.update({item})\n",
    "    return set1\n",
    "def get_section_matiral_index(sections,extracts:set):\n",
    "    \"\"\"\n",
    "    获取章节的索引\n",
    "    :param sections:\n",
    "    :param extracts:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    result = {}\n",
    "    for extract in extracts:\n",
    "        section_matriels = []\n",
    "        for label,sections_ in sections.items():\n",
    "            regex = re.compile(extract)\n",
    "            for index in range(len(sections_)):\n",
    "                if len(regex.findall(sections_[index][1])):\n",
    "                    start = sections_[index][0]\n",
    "                    if index != len(sections_) - 1:\n",
    "                        end = sections_[index + 1][0]\n",
    "                    else:\n",
    "                        end = start\n",
    "                    if end - start > 1: # 过滤目录\n",
    "                        section_matriels.append((label,(start,end)))\n",
    "        result[extract] = section_matriels\n",
    "    return result\n",
    "def get_matiral(matriel_index,texts,extracts):\n",
    "    \"\"\"\n",
    "    获得章节素材，进一步处理\n",
    "    :param matriel_index:\n",
    "    :param texts:\n",
    "    :param extracts:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    matirals = {}\n",
    "    for extract in extracts:\n",
    "        temp = []\n",
    "        for label,(start,end) in matriel_index[extract]:\n",
    "            print(texts[label][start:end])\n",
    "            temp.append(texts[label][start:end])\n",
    "        matirals[extract] = temp\n",
    "    return matirals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "IndexError",
     "evalue": "list index out of range",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-937ee20ad34e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0msections\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtext_extract\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mget_sections\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#extracts=get_cross(sections)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mset1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0msectionname\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msectionname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msections\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# matriel_index=get_section_matiral_index(sections,extracts)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "dirname='extract/'\n",
    "sections,text_extract=get_sections(dirname)\n",
    "#extracts=get_cross(sections)\n",
    "set1 = {sectionname[3:] for _, sectionname in list(sections.values())[0]}\n",
    "print(set1)\n",
    "# matriel_index=get_section_matiral_index(sections,extracts)\n",
    "# result=get_matiral(matriel_index,text_extract,extracts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "IndexError",
     "evalue": "list index out of range",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-4f17c842a550>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'供货范围、技术规格、参数与要求'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m11\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "result['供货范围、技术规格、参数与要求'][11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[]"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "import re\n",
    "pattern='采煤机'\n",
    "regex=re.compile(pattern)\n",
    "regex.findall('第2-2项：刮板运输机（SGZ1000/2*1000）')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "\n",
    "\"\"\"\n",
    "需求：将json中的数据转换成csv文件\n",
    "\"\"\"\n",
    "def csv_json(path):\n",
    "    # 1.分别 读，创建文件\n",
    "    json_fp = open(path, \"r\",encoding='utf-8')\n",
    "    write_path=path.replace('json','csv')\n",
    "    csv_fp = open(write_path, \"w\",encoding='utf-8-sig')\n",
    "\n",
    "    # 2.提出表头和表的内容\n",
    "    data_list = json.load(json_fp)\n",
    "\n",
    "    sheet_title = data_list[0].keys()\n",
    "     \n",
    "    sheet_data = []\n",
    "    for data in data_list:\n",
    "        sheet_data.append(data.values())\n",
    "\n",
    "    # 3.csv 写入器\n",
    "    writer = csv.writer(csv_fp)\n",
    "\n",
    "    # 4.写入表头\n",
    "    writer.writerow(sheet_title)\n",
    "\n",
    "    # 5.写入内容\n",
    "    writer.writerows(sheet_data)\n",
    "\n",
    "    # 6.关闭两个文件\n",
    "    json_fp.close()\n",
    "    csv_fp.close()\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_json('../extract_dict_lists_采煤机.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<regex.Match object; span=(0, 3), match='第二节'>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "import regex as re \n",
    "pattern_end_2='\\W*第(一|二|三|四|五|六|七|八|九)节'\n",
    "text='第二节 设别'\n",
    "re.match(pattern_end_2,text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tet\n"
    }
   ],
   "source": [
    "stack=[]\n",
    "if not stack:\n",
    "    print('tet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37164bitpython37cpucondadd9741d82b12407eb078040e41a0de29",
   "display_name": "Python 3.7.1 64-bit ('python37cpu': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}